import plotly.graph_objects as go
import streamlit as st
import pandas as pd
import os
import subprocess
import logging
import re
import sys
import os
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from core.auto_predictor import run_prediction
from core.recommender import recommend_options
from core.explainable_ai import explain_prediction

logging.basicConfig(level=logging.INFO)
st.set_page_config(page_title='OmniMarket Prophet', layout='wide')
st.title('ğŸ“Š OmniMarket Prophet - Ø§Ù„ØªÙ†Ø¨Ø¤ ÙˆØ§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø°ÙƒÙŠ')

# Upload CSV file
uploaded_file = st.file_uploader('ğŸ“‚ Ø­Ù…Ù‘Ù„ Ù…Ù„Ù Ø¨ÙŠØ§Ù†Ø§Øª (CSV)', type=['csv'])
symbol = st.text_input('ğŸ” Ø£Ø¯Ø®Ù„ Ø±Ù…Ø² Ø§Ù„Ø³Ù‡Ù… Ù„Ù„Ø¹Ø±Ø¶', value='AAPL')
model_choice = st.selectbox('Ø§Ø®ØªØ± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬', ['xgb', 'lstm'])

# Handle uploaded file
if uploaded_file is not None:
    try:
        df = pd.read_csv(uploaded_file)
        if not all(col in df.columns for col in ['Open', 'High', 'Low', 'Close', 'Volume']):
            st.error('âŒ ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ù…Ù„Ù ØºÙŠØ± ØµØ§Ù„Ø­. ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©: Open, High, Low, Close, Volume')
        else:
            file_path = f'data/historical/{symbol}.csv'
            os.makedirs(os.path.dirname(file_path), exist_ok=True)
            df.to_csv(file_path, index=False)
            st.success(f'âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙƒÙ€ {file_path}')
    except Exception as e:
        st.error(f'âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù: {e}')

# Model training
if uploaded_file is not None and st.button('ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬'):
    try:
        with st.spinner('ğŸ§  Ø¬Ø§Ø±ÙŠ ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬...'):
            log_path = 'models/training_log.txt'
            os.makedirs('models', exist_ok=True)
            result = subprocess.run(['python3', 'training/trainer.py', '--csv', file_path, '--model', 'all'], capture_output=True)
            if result.returncode == 0:
                st.success('âœ… ØªÙ… ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø¨Ù†Ø¬Ø§Ø­!')
                log_content = result.stdout.decode('utf-8')
                st.markdown('### ğŸ“ Ø³Ø¬Ù„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨:')
                st.code(log_content)
            else:
                st.error('âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨')
                st.code(result.stderr.decode('utf-8'))
    except Exception as e:
        st.error(f'âŒ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬: {e}')

# Prediction and Analysis
if st.button('Ø§Ø¨Ø¯Ø£ Ø§Ù„ØªØ­Ù„ÙŠÙ„'):
    try:
        with st.spinner('ğŸ“ˆ ÙŠØªÙ… Ø§Ù„Ø¢Ù† ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª...'):
            results = run_prediction(symbol, model_choice=model_choice)
            if not results:
                st.error('âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù†ØªØ§Ø¦Ø¬.')
            for r in results:
                st.write(f'Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {r["model"]}')
                st.write(f'MAE: {r["mae"]:.2f}')
                st.write(f'Ø¯Ù‚Ø© Ø§Ù„Ø§ØªØ¬Ø§Ù‡: {r["direction_accuracy"]:.2f}%')
                recommendation = recommend_options(100, 105)
                explanation = explain_prediction(symbol, f'ØªØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ Ø¨Ù†Ø³Ø¨Ø© {recommendation["expected_change_pct"]}%', r['model'])
                st.json(recommendation)
                st.info(explanation)
    except Exception as e:
        st.error(f'âŒ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ­Ù„ÙŠÙ„: {e}')
